
# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2025</div><img src='images/TTCMM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MINGLE: Mixtures of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging](https://arxiv.org/pdf/2505.11883) \\
**Zihuan Qiu**, Yi Xu, Chiyuan He, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li
- TTCMM: We formalize Test-Time Continual Model Merging (TTCMM), a new paradigm for merging independently fine-tuned models using unlabeled test data.
- MINGLE: We propose MINGLE, a TTCMM method with adaptive null-space constrained gating, achieving a favorable balance between stability and plasticity.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/DCMI.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Dual-consistency Model Inversion for Non-exemplar Class Incremental Learning](https://openaccess.thecvf.com/content/CVPR2024/papers/Qiu_Dual-Consistency_Model_Inversion_for_Non-Exemplar_Class_Incremental_Learning_CVPR_2024_paper.pdf) \\
**Zihuan Qiu**, Yi Xu, Fanman Meng, Hongliang Li, Linfeng Xu, Qingbo Wu
- DCMI: Uses semantic + domain consistency to generate high-fidelity synthetic old-class images, sharply cutting domain shift.
- Prototypical Routing: Leverages class prototypes to reduce bias and lift old-class accuracy, achieving state-of-the-art results.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Neurocomputing 2023</div><img src='images/ISM-Net.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[ISM-Net: Mining incremental semantics for class incremental learning](https://www.sciencedirect.com/science/article/pii/S0925231222015259) \\
**Zihuan Qiu**, Linfeng Xu, Zhichuan Wang, Qingbo Wu, Fanman Meng, Hongliang Li
- Incremental Semantics Mining (ISM) ‚Äì strips old-class semantics from new-class features, sharply cutting old‚Äìnew confusion and catastrophic forgetting.
- Lightweight Expansion + Old-Model Queue ‚Äì distillation adds a compact extra feature space while a rolling queue preserves early knowledge, delivering SOTA accuracy with minimal memory/compute on CIFAR-100 and ImageNet.
</div>
</div>

- `TMM 2025` [DesCLIP: Robust Continual Adaptation via General Attribute Descriptions for Pretrained Vision-Language Models], Chiyuan He, Zihuan Qiu, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li.
- `ICIP 2025` [DPM-CLIP: Zero-Shot Multimodal Egocentric Activity Recognition based on Dual-Prediction Mechanism], Yukun Chen, Liang Wan, Zihuan Qiu, Mingzhou He, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li.
- `TMM 2025` [Distribution-Level Memory Recall for Continual Learning: Preserving Knowledge and Avoiding Confusion], Shaoxu Cheng, Kanglei Geng, Chiyuan He, Zihuan Qiu, Linfeng Xu, Heqian Qiu, Lanxiao Wang, Qingbo Wu, Fanman Meng, Hongliang Li.
- `ICASSP 2025` [Leveraging Pre-Trained Models for Multimodal Class-Incremental Learning under Adaptive Fusion], Yukun Chen, Zihuan Qiu, Fanman Meng, Hongliang Li, Linfeng Xu, Qingbo Wu.
- `IEEE Sensors Journal 2024` [Continual Egocentric Activity Recognition with Foreseeable-Generalized Visual-IMU Representations], Chiyuan He, Shaoxu Cheng, Zihuan Qiu, Linfeng Xu, Fanman Meng, Qingbo Wu, Hongliang Li.
- `Neurocomputing 2023` [GFR: Generic feature representations for class incremental learning], Zhichuan Wang, Linfeng Xu, Zihuan Qiu, Qingbo Wu, Fanman Meng, Hongliang Li.
- `ICASSP 2023` [MFAT: A multi-level feature aggregated transformer for person re-identification],Bowen Tan, Linfeng Xu, Zihuan Qiu, Qingbo Wu, Fanman Meng.
- `ICIP 2022` [Eldnet: Establishment and refinement of edge likelihood distributions for camouflaged object detection], Chiyuan He, Linfeng Xu, Zihuan Qiu.
- `SPIE Medical Imaging 2022` [BDG-Net: boundary distribution guided network for accurate polyp segmentation](https://arxiv.org/pdf/2201.00767), **Zihuan Qiu**, Zhichuan Wang, Miaomiao Zhang, Ziyong Xu, Jie Fan, Linfeng Xu.
